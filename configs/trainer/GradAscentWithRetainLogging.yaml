defaults:
  - finetune

handler: GradAscentWithRetainLogging
method_args:
  gamma: 1.0
  alpha: 1.0
  retain_loss_type: NLL
